{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/Ektagavas/CVSummerSchool2021/blob/main/Stereo/01_Stereo_basics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2Nnq3eeff1SK"
   },
   "source": [
    "# Stereo Estimation Using Patch Matching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_i4Mrjuof1SL"
   },
   "source": [
    "Depth Estimation in computer vision is most commonly done via stereo vision in which images from two cameras are used to triangulate and estimate distances.\n",
    "\n",
    "The simplest example of stereo pair images is vision in left eye and right eye. Both eyes sees a real world 3D point but the image point in right image plane is shifted horizantally w.r.t left image plane.\n",
    "\n",
    "Another instance of Stereo Problem is the roadside trees move faster while you are travelling when compared to farther mountains. \n",
    "The following link helps in better understanding of problem. https://web.archive.org/web/20180827092736/http://www.cs.tut.fi/~suominen/SGN-1656-stereo/stereo_instructions.pdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jjoSUco8f1SN",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import PIL\n",
    "from IPython.display import Image\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rOR768fGf4Ke",
    "tags": []
   },
   "outputs": [],
   "source": [
    "!wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=13G6FvNhz8AZQwrPVjnraKvjxOoQjEjrv' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=13G6FvNhz8AZQwrPVjnraKvjxOoQjEjrv\" -O data.zip && rm -rf /tmp/cookies.txt\n",
    "!unzip data.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "id": "mllIEHjQf1SO",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Display Left image\n",
    "Image(filename=\"./data/left_t.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "id": "a3a5Vhqmf1SQ",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Display Right Image. Observe the difference in both images\n",
    "Image(filename=\"./data/right_t.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "58-NuBnGf1SR"
   },
   "source": [
    "# Geometry Of Stereo Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A6bcF7GMf1SR"
   },
   "source": [
    "Let us assume the two cameras which were used to capture Left and Right images have same focal length $f$. \n",
    "\n",
    "Let the two cameras are separated by a baseline distance $B$ as shown in the figure below.\n",
    "\n",
    "Since, both cameras have same focal length their image planes are separated along horizantal axis only.\n",
    "\n",
    "Let P be the real world point which is at distance $Z$ from both the cameras.\n",
    "\n",
    "$Disparity$ is the displacement of an Image point of a real world point in one image w.r.t other image. \n",
    "\n",
    "From similar triangles, we can figure out that $x_1$ - $x_2$=$Bf/Z$\n",
    "\n",
    "We can realize that disparity is inversely proportional to the distance of point from the cameras. Farther the point the smaller is disparity. Hence, mountains appear to move slowly while roadside trees move rapidly\n",
    "\n",
    "<img src='https://github.com/Ektagavas/CVSummerSchool2021/blob/main/Stereo/images/Disparity.png?raw=1' width=\"450\">\n",
    "\n",
    "The basic step in computing stereo is Identifying common points in camera views. We have appearance as the clue to identify them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "id": "TNtTJmdKf1ST",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "left = cv2.imread(\"./data/left_t.png\", 0)\n",
    "right = cv2.imread(\"./data/right_t.png\", 0)\n",
    "print(\"Left Shape \" + str(left.shape))\n",
    "print(\"Right Shape \" + str(right.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "id": "ETH8mmxZf1SU",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Display and save the image\n",
    "def match(disparity, save_to_file_path):\n",
    "    plt.imshow(disparity, cmap=\"gray\")\n",
    "\n",
    "    if save_to_file_path != \"\":\n",
    "        cv2.imwrite(save_to_file_path, disparity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BM3II1Uef1SU"
   },
   "source": [
    "# How Images can be matched\n",
    "\n",
    "The image matching problems can be divided into two classes of algorithms. \n",
    "\n",
    "a. Correlation Based Algorithms which produces dense correspondence (pixel to pixel)\n",
    "<br>\n",
    "b. Features Based Algorithms which produces sparse correspondences\n",
    "\n",
    "Images in RGB space has color as characteristic. Hence, having color as heuristic to match several images makes sense.\n",
    "But, by matching individual pixel colours, matching will be too noisy.\n",
    "\n",
    "Match a (small) neighbourhood of colours from one image to a similar neighbourhood in other. We will typically need geometric constraints to reduce the size of the search space\n",
    "\n",
    "Algorithm:\n",
    "Extract a patch in the left image centered around (x,y).\n",
    "<br>\n",
    "Because of the assumptions made, search for an \"appropriate\" patch in the right image along the X directions of the patch in left image.\n",
    "<br>\n",
    "At each location (x,y) store the displacement of appropriate patch from the right patch\n",
    "\n",
    "Because of assumptions made, the procedure will work if local surface is fronto-parallel and images have similar magnification i.e. skewed images or two differently zoomed images might face issues. Why?\n",
    "\n",
    "However, if we have left and right images has variance in contrast etc. matching pixel neighbourhood might not help as the color of the texture in the patch is no longer same and matches will be noisy.\n",
    "\n",
    "Hence, matching in feature space will help as features will be invariant to variations in illumination, scale, rotations etc. \n",
    "\n",
    "Let's match images. But How do you decide appropriate patch? We choose them using various similarity measures as mentioned below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qq6zsqeef1SW"
   },
   "source": [
    "# Sum of Squared Distances\n",
    "\n",
    "This is the most popular matching score. It is also used in deriving Harris Corner. Search for a patch in the right image along X direction whose Euclidean distance is very small to the patch in left image\n",
    "\n",
    "<img src='https://github.com/Ektagavas/CVSummerSchool2021/blob/main/Stereo/images/ssd.png?raw=1' width=\"350\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "id": "WlLv-1G_f1SX",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def ssd_match(left, right, patch, search_range):\n",
    "    \"\"\"\n",
    "    Assume both left and right images have same dimensions\n",
    "    :type left: OpenCv Image\n",
    "\n",
    "    Params:\n",
    "    left: Left image\n",
    "    right: Right Image which is shifted along X-Axis\n",
    "    Patch: Size of a patch around each pixel\n",
    "    search_range: How many pixels in the right image are searched for a particular pixel in left image\n",
    "    \"\"\"\n",
    "\n",
    "    # Can reduce image size by half\n",
    "    # left = cv2.resize(left, (0, 0), fx=0.5, fy=0.5)\n",
    "    # right = cv2.resize(right, (0, 0), fx=0.5, fy=0.5)\n",
    "    w, h = left.shape\n",
    "\n",
    "    # Store the displacement of each pixel in disparity\n",
    "    disparity = np.zeros((w, h), np.uint8)\n",
    "    disparity.shape = w, h\n",
    "    patch_half = int(patch / 2)\n",
    "\n",
    "    offset_adjust = 255 / search_range\n",
    "    # Each Column\n",
    "    for y in range(patch_half, w - patch_half - 1):\n",
    "        # print y\n",
    "        # Each Row\n",
    "        for x in range(patch_half, h - patch_half - 1):\n",
    "            best_match = 0  # best_match stores the displacement of appropriate patch\n",
    "            best_score = 65534  # best_score stores the current best score. Smaller the score the better is the patch\n",
    "            # Extract patch from left image around (x,y). patch_half pixels to the left, right, top and above\n",
    "            left_patch = left[\n",
    "                y - patch_half : y + patch_half, x - patch_half : x + patch_half\n",
    "            ]\n",
    "            # How many pixels to search\n",
    "            for search in range(search_range):\n",
    "                ssd = 0\n",
    "                ssd_temp = 0\n",
    "                if x + search + patch_half < h + 1:\n",
    "                    # slide one pixel in the right image and extract the patch around (x+search, y)\n",
    "                    right_patch = right[\n",
    "                        y - patch_half : y + patch_half,\n",
    "                        x + search - patch_half : (x + search + patch_half),\n",
    "                    ]\n",
    "                    for i in range(left_patch.shape[0]):\n",
    "                        for j in range(right_patch.shape[1]):\n",
    "                            \"\"\"\n",
    "                            Sum of Squared distances is computed here\n",
    "                            \"\"\"\n",
    "                            ssd_temp = int(left_patch[i, j]) - int(right_patch[i, j])\n",
    "                            ssd += ssd_temp * ssd_temp\n",
    "                    # If the current score is less than the previous best score, then it is a better match\n",
    "                    if ssd < best_score:\n",
    "                        best_score = ssd\n",
    "                        best_match = search\n",
    "            disparity[y, x] = best_match * offset_adjust\n",
    "    return disparity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "id": "bVTewvIyf1Sa",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "dis_ssd = ssd_match(left, right, 8, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "id": "xXPbwP5Lf1Sa",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "match(dis_ssd, \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S89P_3Y0f1Sb"
   },
   "source": [
    "# Normalized Cross Correlation\n",
    "\n",
    "When a scene is imaged by different sensors, or under different illumination intensities, the SSD can be large for windows representing the same area in the scene\n",
    "\n",
    "A solution is to normalize the pixels in the patches before comparing them by subtracting the mean of the patch intensities and dividing by standard deviation\n",
    "\n",
    "<img src='https://github.com/Ektagavas/CVSummerSchool2021/blob/main/Stereo/images/ncc_1.png?raw=1' width=\"350\">\n",
    "<img src='https://github.com/Ektagavas/CVSummerSchool2021/blob/main/Stereo/images/ncc_2.png?raw=1' width=\"350\">\n",
    "\n",
    "    where C is Correlation\n",
    "    \n",
    "Important point about NCC:\n",
    "<br>\n",
    "Score values range from 1 (perfect match) to -1 (completely anti-correlated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ODRHvazdf1Sd",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def ncc_match(left, right, patch, search_range):\n",
    "    \"\"\"\n",
    "    Assume both left and right images have same dimensions\n",
    "    :type left: OpenCv Image\n",
    "    \"\"\"\n",
    "\n",
    "    # left = cv2.resize(left, (0, 0), fx=0.5, fy=0.5)\n",
    "    # right = cv2.resize(right, (0, 0), fx=0.5, fy=0.5)\n",
    "    w, h = left.shape\n",
    "\n",
    "    disparity = np.zeros((w, h), np.uint8)\n",
    "    disparity.shape = w, h\n",
    "    patch_half = int(patch / 2)\n",
    "\n",
    "    offset_adjust = 255 / search_range\n",
    "\n",
    "    for y in range(patch_half, w - patch_half - 1):\n",
    "        # print y\n",
    "        for x in range(patch_half, h - patch_half - 1):\n",
    "            # Extract Left Patch\n",
    "            left_patch = left[\n",
    "                y - patch_half : y + patch_half, x - patch_half : x + patch_half\n",
    "            ]\n",
    "            # Compute Mean of the left patch\n",
    "            left_mu = np.mean(left_patch)\n",
    "            # Compute the Standard deviation of the left patch\n",
    "            left_sigma = np.std(left_patch)\n",
    "            # Best Score should be greater for best match unlike SSD where it should be smaller\n",
    "            best_score = -1\n",
    "            for search in range(search_range):\n",
    "                if x + search + patch_half < h + 1:\n",
    "                    # Extract right patch\n",
    "                    right_patch = right[\n",
    "                        y - patch_half : y + patch_half,\n",
    "                        x + search - patch_half : (x + search + patch_half),\n",
    "                    ]\n",
    "                    # Mean of the right patch\n",
    "                    right_mu = np.mean(right_patch)\n",
    "                    # Std of the right Patch\n",
    "                    right_sigma = np.std(right_patch)\n",
    "                    num = np.mean((left_patch - left_mu) * (right_patch - right_mu))\n",
    "                    denom = left_sigma * right_sigma\n",
    "                    score = num / denom\n",
    "                # Assign the current score as the best score if it is greater than the previous best score\n",
    "                if score > best_score:\n",
    "                    best_score = score\n",
    "                    best_match = search\n",
    "            disparity[y, x] = best_match * offset_adjust\n",
    "    return disparity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "id": "jIEoZiNaf1Sf",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "dis_ncc = ncc_match(left, right, 8, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "id": "5vyagxEAf1Sg",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "match(dis_ncc, \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hhpTrQC9f1Sh"
   },
   "source": [
    "# Cosine Similarity\n",
    "\n",
    "Consider each patch as a vector. The dot product between the left patch and right patch gives the similarity information\n",
    "\n",
    "<img src='https://github.com/Ektagavas/CVSummerSchool2021/blob/main/Stereo/images/cosine.png?raw=1' width=\"350\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fhYJVRp0f1Si",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def cosine_match(left, right, patch, search_range):\n",
    "    \"\"\"\n",
    "    Assume both left and right images have same dimensions\n",
    "    :type left: OpenCv Image\n",
    "    \"\"\"\n",
    "\n",
    "    # left = cv2.resize(left, (0, 0), fx=0.5, fy=0.5)\n",
    "    # right = cv2.resize(right, (0, 0), fx=0.5, fy=0.5)\n",
    "    w, h = left.shape\n",
    "\n",
    "    disparity = np.zeros((w, h), np.uint8)\n",
    "    disparity.shape = w, h\n",
    "    patch_half = int(patch / 2)\n",
    "    eps = 0.00001\n",
    "    offset_adjust = 255 / search_range\n",
    "\n",
    "    for y in range(patch_half, w - patch_half - 1):\n",
    "        # print y\n",
    "        for x in range(patch_half, h - patch_half - 1):\n",
    "            left_patch = left[\n",
    "                y - patch_half : y + patch_half, x - patch_half : x + patch_half\n",
    "            ]\n",
    "            best_score = -1\n",
    "            for search in range(search_range):\n",
    "                if x + search + patch_half < h + 1:\n",
    "                    # Convert left patch to a vector\n",
    "                    left_flatten = left_patch.flatten()[0]\n",
    "                    # Right patch\n",
    "                    right_patch = right[\n",
    "                        y - patch_half : y + patch_half,\n",
    "                        x + search - patch_half : (x + search + patch_half),\n",
    "                    ]\n",
    "                    # Convert right patch to a vector\n",
    "                    right_flatten = right_patch.flatten()[0]\n",
    "                    # Compute Dot product\n",
    "                    dot = np.dot(left_flatten, right_flatten)\n",
    "                    # Compute magnitudes\n",
    "                    left_magnitude = np.linalg.norm(left_flatten)\n",
    "                    right_magnitude = np.linalg.norm(right_flatten)\n",
    "                    score = dot / (left_magnitude * right_magnitude + eps)\n",
    "\n",
    "                if score > best_score:\n",
    "                    best_score = score\n",
    "                    best_match = search\n",
    "            disparity[y, x] = best_match * offset_adjust\n",
    "    return disparity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "id": "W_-1TSpSf1Sk",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "dis_cos = cosine_match(left, right, 8, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "id": "GtBhzKu-f1Sl",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "match(dis_cos, \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xlpBNeLlf1Sm"
   },
   "source": [
    "# In Feature Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "id": "FxFg5SFjf1Sn",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "left_img = np.float32(left) / 255.0\n",
    "gx_left = cv2.Sobel(left_img, cv2.CV_32F, 1, 0, ksize=5)\n",
    "gy_left = cv2.Sobel(left_img, cv2.CV_32F, 0, 1, ksize=5)\n",
    "laplacian_left = cv2.Laplacian(left, cv2.CV_64F)\n",
    "\n",
    "mag_left, angle_left = cv2.cartToPolar(gx_left, gy_left, angleInDegrees=True)\n",
    "\n",
    "right_img = np.float32(right) / 255.0\n",
    "gx_right = cv2.Sobel(right_img, cv2.CV_32F, 1, 0, ksize=5)\n",
    "gy_left = cv2.Sobel(right_img, cv2.CV_32F, 0, 1, ksize=5)\n",
    "\n",
    "mag_right, angle_right = cv2.cartToPolar(gx_left, gy_left, angleInDegrees=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_CAS4wCwf1So",
    "tags": []
   },
   "outputs": [],
   "source": [
    "dis_ncc_sobel = ssd_match(mag_left, mag_right, 8, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "id": "Jw7ZRtwlf1Sp",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "match(dis_ncc_sobel, \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SzDl9Z8Rf1Sp"
   },
   "source": [
    "# What happens if you just take the histogram of normal gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "id": "7v_8EIo9f1Sq",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def gradient_match(left_ang, right_ang, num_bins, search_range, patch):\n",
    "\n",
    "    metric = \"ssd\"\n",
    "    \"\"\"\n",
    "    Assume both left and right images have same dimensions\n",
    "    :type left: OpenCv Image\n",
    "    \"\"\"\n",
    "\n",
    "    left_ang = cv2.resize(left_ang, (0, 0), fx=0.5, fy=0.5)\n",
    "    right_ang = cv2.resize(right_ang, (0, 0), fx=0.5, fy=0.5)\n",
    "    w, h = left_ang.shape\n",
    "    disparity = np.zeros((w, h), np.uint8)\n",
    "    disparity.shape = w, h\n",
    "\n",
    "    # Spacing between bins\n",
    "    bin_offset = int(360 / num_bins)\n",
    "    # Bin values\n",
    "    bins_vals = range(0, 360, bin_offset)\n",
    "    patch_half = int(patch / 2)\n",
    "    offset_adjust = 255 / search_range\n",
    "\n",
    "    for y in range(patch_half, w - patch_half - 1):\n",
    "        for x in range(patch_half, h - patch_half - 1):\n",
    "            left_patch = left_ang[\n",
    "                y - patch_half : y + patch_half, x - patch_half : x + patch_half\n",
    "            ]\n",
    "            # Compute histogram of left patch\n",
    "            left_hist = np.histogram(left_patch, bins_vals)[0][0]\n",
    "            best_score = 65534\n",
    "            for search in range(search_range):\n",
    "                if x + search + patch_half < h + 1:\n",
    "                    # Right patch\n",
    "                    right_patch = right_ang[\n",
    "                        y - patch_half : y + patch_half,\n",
    "                        x + search - patch_half : (x + search + patch_half),\n",
    "                    ]\n",
    "                    # Compute histogram of right image\n",
    "                    right_hist = np.histogram(right_patch, bins_vals)[0][0]\n",
    "\n",
    "                    ssd_t = np.linalg.norm(left_hist - right_hist)\n",
    "                    score = ssd_t\n",
    "                    if score < best_score:  # and score != 0:\n",
    "                        best_score = score\n",
    "                        best_match = search\n",
    "                # print best_score\n",
    "            disparity[y, x] = best_match * offset_adjust\n",
    "            # disparity[y, x] = best_match\n",
    "    return disparity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "id": "ue0BedjDf1Sr",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "dis_ang = gradient_match(angle_left, angle_right, 6, 15, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "id": "lsn7aChvf1Ss",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "match(dis_ang, \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xI-PlTKFf1St"
   },
   "source": [
    "# Using OpenCV\n",
    "\n",
    "It uses the technique described in the paper \"Stereo processing by semiglobal matching and mutual information.\"\n",
    "\n",
    "[HirschmÃ¼ller](https://www.ncbi.nlm.nih.gov/pubmed/18084062)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "id": "madsCc7if1Su",
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "imgL = right\n",
    "imgR = left\n",
    "\n",
    "stereo = cv2.StereoBM_create(numDisparities=16, blockSize=15)\n",
    "disparity = stereo.compute(imgL, imgR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "id": "7Hf1uIQ6f1Sv",
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "match(disparity, \"\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "name": "01_Stereo_basics.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
